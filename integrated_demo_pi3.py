import gradio as gr
import requests
import time
import json
from PIL import Image
from io import BytesIO
import os
import sys
import shutil
from datetime import datetime
import torch
import numpy as np
import glob
import gc
import re
from openai import OpenAI

# Add Pi3 to path
sys.path.append(os.path.join(os.path.dirname(__file__), "Pi3"))

try:
    from pi3.models.pi3 import Pi3
    from pi3.utils.basic import load_images_as_tensor
    from pi3.utils.geometry import depth_edge
    # Import visualization utils from demo_gradio.py
    # We need to make sure demo_gradio is importable. 
    # Since it is in the same folder as pi3 package, and we added that folder to sys.path
    import demo_gradio
    from demo_gradio import predictions_to_glb
except ImportError as e:
    print(f"Error importing Pi3 modules: {e}")
    print("Please ensure the 'Pi3' directory is present and contains the necessary files.")
    sys.exit(1)

# --- ModelScope Configuration ---
API_KEY = "your ModelScope API key"  # replace with your ModelScope API key
BASE_URL = 'https://api-inference.modelscope.cn/'
HEADERS = {
    "Authorization": f"Bearer {API_KEY}",
    "Content-Type": "application/json",
}

# --- Pi3 Model Setup ---
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Initializing and loading Pi3 model on {device}...")

try:
    model = Pi3.from_pretrained("yyfz233/Pi3")
    model.eval()
    model = model.to(device)
    print("Pi3 Model loaded successfully.")
except Exception as e:
    print(f"Error loading Pi3 model: {e}")
    model = None

# --- Helper Functions ---

def upload_image_to_get_url(file_path):
    url = 'https://img.scdn.io/api/v1.php'
    try:
        with open(file_path, 'rb') as f:
            files = {'image': f}
            data = {'cdn_domain': 'img.scdn.io'}
            response = requests.post(url, files=files, data=data)
            response.raise_for_status()
            print("å›¾ç‰‡ä¸Šä¼ æˆåŠŸï¼Œè·å–URLä¸º", response.json()['url'])
            return response.json()['url']
    except Exception as e:
        print(f"Failed to upload image: {e}")
        return None

def check_is_medical(image_url):
    client = OpenAI(
        base_url='https://api-inference.modelscope.cn/v1',
        api_key=API_KEY,
    )

    try:
        response = client.chat.completions.create(
            model='Qwen/Qwen3-VL-8B-Instruct',
            messages=[{
                'role': 'user',
                'content': [{
                    'type': 'text',
                    'text': 'è¿™å¼ å›¾æ˜¯å¦ä¸¥æ ¼å’ŒåŒ»å­¦æœ‰å…³ï¼Ÿè¯·ä½ å›ç­”ï¼Œä½ åªéœ€è¦å›ç­”æ˜¯æˆ–è€…ä¸æ˜¯',
                }, {
                    'type': 'image_url',
                    'image_url': {
                        'url': image_url,
                    },
                }],
            }],
            stream=False
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"Medical check failed: {e}")
        # In case of API error, we might want to allow it to proceed or fail. 
        # Here we return Error to let the caller decide, or just return empty string to pass.
        # Let's return "Error" and log it.
        return "Error"

def handle_local_upload(files, progress=gr.Progress()):
    gr.Info("æœ¬åœ°ä¸Šä¼ æ¨¡å¼ï¼šç›´æ¥ä¸Šä¼ å¤šå¼ å·²æœ‰å›¾ç‰‡ç”¨äºé‡å»ºï¼Œä¸è¿›è¡ŒAIç”Ÿæˆï¼Œå¦‚æœä½ å¯¹å›¾åƒå¾ˆæœ‰ä¿¡å¿ƒï¼Œè¯·ä½¿ç”¨å®ƒï¼", duration=5)
    if not files:
        raise gr.Error("è¯·è‡³å°‘ä¸Šä¼ ä¸€å¼ å›¾ç‰‡ã€‚")
        
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    session_dir = os.path.join(os.path.dirname(__file__), "generated_data", f"session_upload_{timestamp}")
    images_dir = os.path.join(session_dir, "images")
    os.makedirs(images_dir, exist_ok=True)
    
    saved_files = []
    progress(0, desc="æ­£åœ¨å¤„ç†ä¸Šä¼ ...")
    for i, file in enumerate(files):
        # Gradio passes file objects with .name as path
        file_path = file.name
        filename = os.path.basename(file_path)
        dest_path = os.path.join(images_dir, filename)
        shutil.copy(file_path, dest_path)
        saved_files.append(dest_path)
        
    return session_dir, saved_files, f"âœ… å·²ä¸Šä¼  {len(saved_files)} å¼ å›¾ç‰‡ã€‚å‡†å¤‡é‡å»ºã€‚", gr.update(interactive=True)

def translate_prompt(text):
    if not text:
        return text
    
    # Check if text contains Chinese characters
    if re.search(r'[\u4e00-\u9fff]', text):
        print(f"æ£€æµ‹åˆ°ä¸­æ–‡æç¤ºè¯: {text}ï¼Œæ­£åœ¨ç¿»è¯‘...")
        gr.Info(f"æ£€æµ‹åˆ°ä¸­æ–‡æç¤ºè¯ï¼Œæ­£åœ¨ç¿»è¯‘: {text}")
        
        client = OpenAI(
            base_url='https://api-inference.modelscope.cn/v1',
            api_key=API_KEY,
        )
        
        # set extra_body for thinking control
        extra_body = {
            # enable thinking, set to False to disable test
            "enable_thinking": True,
            # use thinking_budget to contorl num of tokens used for thinking
            # "thinking_budget": 4096
        }
        
        try:
            response = client.chat.completions.create(
                model='Qwen/Qwen3-8B',
                messages=[
                    {
                        'role': 'user',
                        'content': f'ä¸¥æ ¼å°†ä»¥ä¸‹å¥å­ç¿»è¯‘æˆè‹±æ–‡ï¼Œä¸éœ€è¦ä»»ä½•é¢å¤–å†…å®¹: "{text}"'
                    }
                ],
                stream=True,
                extra_body=extra_body
            )
            
            translated_text = ""
            for chunk in response:
                if chunk.choices:
                    answer_chunk = chunk.choices[0].delta.content
                    if answer_chunk:
                        translated_text += answer_chunk
            
            translated_text = translated_text.strip()
            # Remove quotes if present in the output (sometimes models add them)
            if translated_text.startswith('"') and translated_text.endswith('"'):
                translated_text = translated_text[1:-1]
            
            print(f"ç¿»è¯‘ç»“æœ: {translated_text}")
            gr.Info(f"ç¿»è¯‘å®Œæˆ: {translated_text}")
            return translated_text
        except Exception as e:
            print(f"Translation failed: {e}")
            return text
    return text

def generate_multiview_images(image_url, additional_prompt="", progress=gr.Progress()):
    if not image_url:
        return None, None, "è¯·è¾“å…¥å›¾ç‰‡ URLã€‚"

    # Translate prompt if needed
    additional_prompt = translate_prompt(additional_prompt)

    # Medical Check
    # progress(0, desc="æ­£åœ¨æ£€æµ‹å›¾ç‰‡æ˜¯å¦ä¸åŒ»å­¦ç›¸å…³...")
    answer = check_is_medical(image_url)
    print(f"Medical check result: {answer}")
    
    if answer == "Error":
        return None, None, "åŒ»å­¦æ£€æµ‹å¤±è´¥ï¼ˆAPI é”™è¯¯ï¼‰å¤§æ¦‚ç‡ä¸ºè¿æ¥é—®é¢˜ï¼Œè¯·ç¨åé‡è¯•ã€‚"

    negative_keywords = ["ä¸æ˜¯", "å¦", "no", "No", "NO"]
    # Check if any negative keyword is in the answer
    if any(keyword in answer for keyword in negative_keywords):
        return None, None, "MEDICAL_ERROR"

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    # Create a session directory
    session_dir = os.path.join(os.path.dirname(__file__), "generated_data", f"session_{timestamp}")
    images_dir = os.path.join(session_dir, "images")
    os.makedirs(images_dir, exist_ok=True)
    
    # Views configuration
    views = ["top view", "left side view", "right side view", "bottom view", "back view"]
    view_trans = {
        "top view": "é¡¶è§†å›¾", "left side view": "å·¦è§†å›¾", "right side view": "å³è§†å›¾", 
        "bottom view": "åº•è§†å›¾", "back view": "åè§†å›¾"
    }
    view_filename_map = {
        "top view": "top_view.jpg",
        "left side view": "left_view.jpg",
        "right side view": "right_view.jpg",
        "bottom view": "bottom_view.jpg",
        "back view": "back_view.jpg"
    }
    
    generated_files = []
    
    # 1. Generate Front View (White Background)
    progress(0, desc="æ­£åœ¨ç”Ÿæˆç™½åº•æ­£è§†å›¾...")
    front_prompt = f"Generate the front view of the object in the image. The image must have a pure white background and contain strictly a single object. Ensure the object is identical to the original in terms of morphology, geometry, and texture. Photorealistic, full color, high resolution, rich texture details, accurate lighting consistent with a front-facing perspective. {additional_prompt}"
    
    try:
        # Submit Task for Front View
        payload = {
            "model": 'Qwen/Qwen-Image-Edit-2509',
            "prompt": front_prompt,
            "image_url": [image_url]
        }
        response = requests.post(
            f"{BASE_URL}v1/images/generations",
            headers={**HEADERS, "X-ModelScope-Async-Mode": "true"},
            data=json.dumps(payload, ensure_ascii=False).encode('utf-8')
        )
        response.raise_for_status()
        task_id = response.json()["task_id"]
        
        # Poll for result
        generated_front_url = None
        while True:
            result = requests.get(
                f"{BASE_URL}v1/tasks/{task_id}",
                headers={**HEADERS, "X-ModelScope-Task-Type": "image_generation"},
            )
            result.raise_for_status()
            data = result.json()
            
            if data["task_status"] == "SUCCEED":
                generated_front_url = data["output_images"][0]
                break
            elif data["task_status"] == "FAILED":
                print(f"Failed to generate front view: {data}")
                return None, None, "GENERATION_FAILED:æ­£è§†å›¾"
            
            time.sleep(2)
            
        # Download and save the generated front view
        response = requests.get(generated_front_url)
        response.raise_for_status()
        front_img = Image.open(BytesIO(response.content))
        if front_img.mode == 'RGBA':
            front_img = front_img.convert('RGB')
            
        front_path = os.path.join(images_dir, "front_view.jpg")
        front_img.save(front_path)
        generated_files.append(front_path)
        
        # Update image_url to use the generated one for subsequent views
        image_url = generated_front_url
        
    except Exception as e:
        print(f"Error generating front view: {e}")
        return None, None, f"GENERATION_ERROR:æ­£è§†å›¾:{str(e)}"

    # 2. Generate Other Views
    view_prompts = {
        "top view": "Generate the top view of the object in the image, as seen directly from above. The image must have a pure white background and contain strictly a single object. Focus on the upper surface texture, color, and geometry. Ensure the object's proportions and morphology are consistent with the original object. Photorealistic, full color, high resolution, detailed top-down perspective.",
        "left side view": "Generate the left side view of the object in the image, as seen directly from left. The image must have a pure white background and contain strictly a single object. Focus on the side geometry, depth, and texture details. Ensure the object is identical to the original in color and material. Photorealistic, full color, accurate side profile.",
        "right side view": "Generate the right side view of the object in the image, as seen directly from right. The image must have a pure white background and contain strictly a single object. Focus on the side geometry, depth, and texture details. Ensure the object is identical to the original in color and material. Photorealistic, full color, accurate side profile.",
        "bottom view": "Generate the bottom view of the object in the image, as seen directly from below. The image must have a pure white background and contain strictly a single object. Focus on the base texture, color, and structure. Ensure the object's proportions and morphology are consistent with the original object. Photorealistic, full color, detailed bottom-up perspective.",
        "back view": "Generate the back view of the object in the image, showing the rear side. The image must have a pure white background and contain strictly a single object. Focus on the rear texture, color, and geometry details. Ensure the object is identical to the original. Photorealistic, full color, consistent with the front view's scale and style."
    }

    for i, view in enumerate(views):
        view_name_cn = view_trans.get(view, view)
        progress((i + 1) / (len(views) + 1), desc=f"æ­£åœ¨ç”Ÿæˆ {view_name_cn}...")
        
        prompt = view_prompts.get(view, f"Generate the {view} of the object in the image, pure white background, strictly single object, identical to the original object, high quality, {additional_prompt}")
        
        try:
            # Submit Task
            payload = {
                "model": 'Qwen/Qwen-Image-Edit-2509',
                "prompt": prompt,
                "image_url": [image_url]
            }
            response = requests.post(
                f"{BASE_URL}v1/images/generations",
                headers={**HEADERS, "X-ModelScope-Async-Mode": "true"},
                data=json.dumps(payload, ensure_ascii=False).encode('utf-8')
            )
            response.raise_for_status()
            task_id = response.json()["task_id"]
            
            # Poll for result
            while True:
                result = requests.get(
                    f"{BASE_URL}v1/tasks/{task_id}",
                    headers={**HEADERS, "X-ModelScope-Task-Type": "image_generation"},
                )
                result.raise_for_status()
                data = result.json()
                
                if data["task_status"] == "SUCCEED":
                    output_url = data["output_images"][0]
                    img_data = requests.get(output_url).content
                    image = Image.open(BytesIO(img_data))
                    
                    if image.mode == 'RGBA':
                        image = image.convert('RGB')
                    
                    filename = view_filename_map[view]
                    save_path = os.path.join(images_dir, filename)
                    image.save(save_path)
                    generated_files.append(save_path)
                    break
                elif data["task_status"] == "FAILED":
                    print(f"Failed to generate {view}: {data}")
                    return None, None, f"GENERATION_FAILED:{view_name_cn}"
                
                time.sleep(2)
                
        except Exception as e:
            print(f"Error generating {view}: {e}")
            return None, None, f"GENERATION_ERROR:{view_name_cn}:{str(e)}"
            
    # Return the session directory (parent of 'images') and list of files
    return session_dir, generated_files, "âœ… ç”Ÿæˆå®Œæˆï¼ç°åœ¨å¯ä»¥é‡å»º 3D æ¨¡å‹ã€‚"

def run_pi3_inference(target_dir, conf_thres, show_cam, mask_sky, mask_black_bg, mask_white_bg, prediction_mode, frame_filter, point_size, progress=gr.Progress()):
    if model is None:
        raise gr.Error("Pi3 æ¨¡å‹æœªåŠ è½½ã€‚")
        
    if not target_dir or not os.path.exists(target_dir):
        raise gr.Error("æœªæ‰¾åˆ°ç›®æ ‡ç›®å½•ã€‚è¯·å…ˆç”Ÿæˆå›¾ç‰‡ã€‚")
        
    print(f"Processing images from {target_dir}")
    progress(0.1, desc="æ­£åœ¨åŠ è½½å›¾ç‰‡...")
    
    # Prepare images
    image_names = glob.glob(os.path.join(target_dir, "images", "*"))
    image_names = sorted(image_names)
    if len(image_names) == 0:
        raise gr.Error("ç›®æ ‡ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾ç‰‡ã€‚")

    # Load and preprocess
    try:
        imgs = load_images_as_tensor(os.path.join(target_dir, "images"), interval=1).to(device)
    except Exception as e:
        raise gr.Error(f"åŠ è½½å›¾ç‰‡å‡ºé”™: {e}")
    
    progress(0.3, desc="æ­£åœ¨è¿è¡Œ Pi3 æ¨ç†...")
    
    # Inference
    dtype = torch.bfloat16
    with torch.no_grad():
        with torch.amp.autocast('cuda', dtype=dtype):
            predictions = model(imgs[None]) # Add batch dimension
            
    progress(0.6, desc="æ­£åœ¨åå¤„ç†...")
    
    # Post-process
    predictions['images'] = imgs[None].permute(0, 1, 3, 4, 2)
    predictions['conf'] = torch.sigmoid(predictions['conf'])
    edge = depth_edge(predictions['local_points'][..., 2], rtol=0.03)
    predictions['conf'][edge] = 0.0
    del predictions['local_points']
    
    # Convert to numpy
    for key in predictions.keys():
        if isinstance(predictions[key], torch.Tensor):
            predictions[key] = predictions[key].cpu().numpy().squeeze(0)

    # Save predictions
    np.savez(os.path.join(target_dir, "predictions.npz"), **predictions)
    
    progress(0.8, desc="æ­£åœ¨ç”Ÿæˆ 3D æ¨¡å‹...")
    
    # Generate GLB
    glb_path = os.path.join(target_dir, "output.glb")
    
    # Use predictions_to_glb from demo_gradio
    glbscene = predictions_to_glb(
        predictions,
        conf_thres=conf_thres,
        filter_by_frames=frame_filter,
        show_cam=show_cam,
        point_size=point_size,
    )
    glbscene.export(file_obj=glb_path)
    
    torch.cuda.empty_cache()
    gc.collect()
    
    progress(1.0, desc="å®Œæˆï¼")
    return glb_path

def update_visualization(target_dir, conf_thres, show_cam, mask_sky, mask_black_bg, mask_white_bg, prediction_mode, frame_filter, point_size):
    if not target_dir:
        return None, None
    
    pred_path = os.path.join(target_dir, "predictions.npz")
    if not os.path.exists(pred_path):
        return None, None
        
    try:
        predictions = np.load(pred_path, allow_pickle=True)
        # Convert back to dict of arrays
        pred_dict = {k: predictions[k] for k in predictions.files}
        
        glb_path = os.path.join(target_dir, f"viz_{time.time()}.glb")
        
        glbscene = predictions_to_glb(
            pred_dict,
            conf_thres=conf_thres,
            filter_by_frames=frame_filter,
            show_cam=show_cam,
            point_size=point_size,
        )
        glbscene.export(file_obj=glb_path)
        return glb_path, gr.update(value=glb_path, visible=True)
    except Exception as e:
        print(f"Visualization update failed: {e}")
        return None, None

# --- Gradio UI ---
# Light Bio-tech Theme
theme = gr.themes.Soft(
    primary_hue="cyan",
    secondary_hue="emerald",
    neutral_hue="slate",
).set(
    body_background_fill="#f0f9ff", # Light blue-ish white
    body_text_color="#0f172a",      # Dark slate
    block_background_fill="#ffffff",
    block_border_width="1px",
    block_border_color="#e2e8f0",
    block_shadow="0 4px 6px -1px rgba(0, 0, 0, 0.1)",
    button_primary_background_fill="linear-gradient(90deg, #06b6d4, #10b981)",
    button_primary_background_fill_hover="linear-gradient(90deg, #0891b2, #059669)",
    button_primary_text_color="#ffffff",
    button_primary_border_color="#22d3ee",
    input_background_fill="#f8fafc",
    input_border_color="#cbd5e1",
    input_placeholder_color="#94a3b8",
)

css = """
@import url('https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&family=Rajdhani:wght@300;500;700&display=swap');

:root {
    /* Light Theme Variables (Default) */
    --custom-body-bg: #f0f9ff;
    --custom-body-bg-img: radial-gradient(circle at 50% 50%, #ffffff 0%, #f0f9ff 100%), linear-gradient(0deg, rgba(6, 182, 212, 0.03) 1px, transparent 1px), linear-gradient(90deg, rgba(6, 182, 212, 0.03) 1px, transparent 1px);
    --custom-header-bg: rgba(255, 255, 255, 0.8);
    --custom-header-border: #cffafe;
    --custom-header-shadow: 0 10px 15px -3px rgba(6, 182, 212, 0.1);
    --custom-header-h1: #0e7490;
    --custom-header-p: #475569;
    --custom-panel-bg: rgba(255, 255, 255, 0.9);
    --custom-panel-border: #e2e8f0;
    --custom-panel-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.05);
    --custom-scrollbar-track: #f1f5f9;
    --custom-scrollbar-thumb: #cbd5e1;
    --custom-scrollbar-thumb-hover: #94a3b8;
    --custom-tab-text: #64748b;
    --custom-tab-border: #e2e8f0;
    --custom-status-bg: rgba(16, 185, 129, 0.1);
    --custom-status-color: #059669;
    --custom-status-border: #059669;
}

body.dark-theme {
    /* Dark Theme Variables */
    --custom-body-bg: #000000;
    --custom-body-bg-img: radial-gradient(circle at 50% 50%, #111827 0%, #000000 100%), linear-gradient(0deg, rgba(6, 182, 212, 0.05) 1px, transparent 1px), linear-gradient(90deg, rgba(6, 182, 212, 0.05) 1px, transparent 1px);
    --custom-header-bg: rgba(15, 23, 42, 0.6);
    --custom-header-border: #06b6d4;
    --custom-header-shadow: 0 0 20px rgba(6, 182, 212, 0.2);
    --custom-header-h1: #22d3ee;
    --custom-header-p: #cbd5e1; /* Lighter gray for better visibility */
    --custom-panel-bg: rgba(15, 23, 42, 0.8);
    --custom-panel-border: #1e293b;
    --custom-panel-shadow: 0 0 15px rgba(6, 182, 212, 0.1);
    --custom-scrollbar-track: #0f172a;
    --custom-scrollbar-thumb: #1e293b;
    --custom-scrollbar-thumb-hover: #334155;
    --custom-tab-text: #cbd5e1; /* Lighter gray */
    --custom-tab-border: #1e293b;
    --custom-status-bg: rgba(16, 185, 129, 0.1);
    --custom-status-color: #10b981;
    --custom-status-border: #10b981;

    /* Gradio Overrides for Dark Mode */
    --body-background-fill: #050505;
    --body-text-color: #f1f5f9; /* Very light gray/white */
    --body-text-color-subdued: #cbd5e1;
    --block-background-fill: #0f172a;
    --block-border-color: #1e293b;
    --block-label-text-color: #e2e8f0;
    --block-title-text-color: #f8fafc;
    --input-background-fill: #1e293b; /* Slightly lighter than block bg */
    --input-border-color: #334155;
    --input-placeholder-color: #94a3b8;
    --input-text-color: #f8fafc;
    --prose-text-color: #e2e8f0;
    --prose-header-text-color: #f1f5f9;
    --table-text-color: #e2e8f0;
}

/* Force text color in dark mode for specific elements that might be stubborn */
body.dark-theme .gradio-container label, 
body.dark-theme .gradio-container span, 
body.dark-theme .gradio-container p,
body.dark-theme .gradio-container h1,
body.dark-theme .gradio-container h2,
body.dark-theme .gradio-container h3,
body.dark-theme .gradio-container h4,
body.dark-theme .gradio-container h5,
body.dark-theme .gradio-container h6 {
    color: #e2e8f0;
}

body.dark-theme .header h1 {
    /* Keep the gradient for the main header */
    background: linear-gradient(to right, #06b6d4, #10b981);
    -webkit-background-clip: text;
    -webkit-text-fill-color: transparent;
    color: transparent !important;
}

body.dark-theme .header p {
    color: #cbd5e1 !important;
}

body {
    font-family: 'Rajdhani', sans-serif !important;
    background-color: var(--custom-body-bg);
    background-image: var(--custom-body-bg-img);
    background-size: 100% 100%, 40px 40px, 40px 40px;
    transition: background 0.3s ease;
}

.container { 
    max-width: 95%; 
    margin: auto; 
    padding: 20px;
}

.header { 
    text-align: center; 
    margin-bottom: 30px; 
    padding: 20px;
    background: var(--custom-header-bg);
    border: 1px solid var(--custom-header-border);
    border-radius: 15px;
    box-shadow: var(--custom-header-shadow);
    backdrop-filter: blur(10px);
    transition: all 0.3s ease;
}

.header h1 { 
    font-family: 'Orbitron', sans-serif;
    font-size: 3em !important; 
    color: var(--custom-header-h1);
    text-transform: uppercase;
    letter-spacing: 2px;
    margin-bottom: 10px;
}

.header p { 
    font-size: 1.2em; 
    color: var(--custom-header-p); 
    font-family: 'Rajdhani', sans-serif;
    letter-spacing: 1px;
}

.panel-container {
    background: var(--custom-panel-bg);
    border: 1px solid var(--custom-panel-border);
    border-radius: 15px;
    padding: 20px;
    box-shadow: var(--custom-panel-shadow);
    backdrop-filter: blur(10px);
    transition: all 0.3s ease;
}

.panel-container:hover {
    border-color: #06b6d4;
    box-shadow: 0 0 15px rgba(6, 182, 212, 0.2);
}

/* Custom Scrollbar */
::-webkit-scrollbar {
    width: 10px;
    height: 10px;
}
::-webkit-scrollbar-track {
    background: var(--custom-scrollbar-track); 
}
::-webkit-scrollbar-thumb {
    background: var(--custom-scrollbar-thumb); 
    border-radius: 5px;
}
::-webkit-scrollbar-thumb:hover {
    background: var(--custom-scrollbar-thumb-hover); 
}

/* Button Glow Effects */
button.primary {
    box-shadow: 0 4px 6px -1px rgba(6, 182, 212, 0.3) !important;
    transition: all 0.3s ease !important;
    text-transform: uppercase;
    font-weight: 700 !important;
    letter-spacing: 1px;
}
button.primary:hover {
    box-shadow: 0 10px 15px -3px rgba(6, 182, 212, 0.5) !important;
    transform: translateY(-2px);
}

/* Status Text */
#status {
    font-family: 'Orbitron', sans-serif;
    color: var(--custom-status-color);
    font-size: 1.1em;
    padding: 10px;
    border-left: 3px solid var(--custom-status-border);
    background: var(--custom-status-bg);
    margin-top: 10px;
}

/* Hide progress bar in status output */
#status .progress-text, 
#status .progress-level, 
#status .loading,
#status .meta-text {
    display: none !important;
}

/* Hide download button in Model3D */
.gradio-model3d a[download] { display: none !important; }
.gradio-model3d button[aria-label="Download"] { display: none !important; }
.gradio-model3d .download { display: none !important; }

/* Tabs Styling */
.tabs {
    border-bottom: 1px solid var(--custom-tab-border);
}
.tab-nav button {
    font-family: 'Rajdhani', sans-serif;
    font-weight: 600;
    text-transform: uppercase;
    color: var(--custom-tab-text);
}
.tab-nav button.selected {
    color: #06b6d4 !important;
    border-bottom: 2px solid #06b6d4 !important;
}

/* Theme Toggle Button */
#theme-toggle {
    position: absolute;
    top: 20px;
    right: 5px;
    z-index: 999;
    font-size: 1.5em;
    background: transparent;
    border: none;
    cursor: pointer;
    padding: 5px;
    border-radius: 50%;
    transition: transform 0.3s ease;
    width: 50px;
    height: 50px;
    display: flex;
    align-items: center;
    justify-content: center;
}
#theme-toggle:hover {
    transform: rotate(15deg) scale(1.1);
    background: rgba(128,128,128,0.1);
}
"""

with gr.Blocks(theme=theme, css=css, title="Bio-Tech 3D Reconstruction") as demo:
    # Theme Toggle Button
    theme_toggle_btn = gr.Button("â˜€ï¸", elem_id="theme-toggle")
    
    # JavaScript to toggle theme
    demo.load(
        None,
        None,
        None,
        js="""
        () => {
            const btn = document.getElementById('theme-toggle');
            if (btn) {
                btn.addEventListener('click', () => {
                    document.body.classList.toggle('dark-theme');
                    if (document.body.classList.contains('dark-theme')) {
                        btn.innerText = "ğŸŒ™";
                    } else {
                        btn.innerText = "â˜€ï¸";
                    }
                });
            }
        }
        """
    )

    with gr.Column(elem_classes="container"):
        with gr.Column(elem_classes="header"):
            gr.Markdown("# ğŸ§¬ Bio-Medical 3D Reconstruction Core")
            gr.Markdown("### æ™ºèƒ½åŒ»å­¦å½±åƒä¸‰ç»´é‡å»ºç³»ç»Ÿ | Intelligent Medical Image 3D Reconstruction System")
        
        target_dir_state = gr.State()
        
        with gr.Row(equal_height=False):
            # Left Column: Generation
            with gr.Column(scale=4, elem_classes="panel-container"):
                gr.Markdown("### ğŸ”¬ å½±åƒè¾“å…¥ä¸ç”Ÿæˆ | Image Input & Generation")
                gr.Markdown("---")
                
                with gr.Tabs():
                    with gr.TabItem("ğŸ–¼ï¸ å›¾åƒä¸Šä¼ "):
                        image_url_input = gr.Image(
                            label="ä¸Šä¼ åŒ»å­¦å½±åƒ / Upload Medical Image", 
                            type="filepath",
                            elem_id="upload_img"
                        )
                        with gr.Accordion("âš™ï¸ é«˜çº§é€‰é¡¹ | Advanced Options", open=False):
                            with gr.Row():
                                use_additional_prompt = gr.Checkbox(label="å¯ç”¨å¢å¼ºæç¤ºè¯", value=False)
                                additional_prompt_input = gr.Textbox(label="æç¤ºè¯", placeholder="è¾“å…¥é¢å¤–çš„ç”Ÿç‰©ç‰¹å¾æè¿°", visible=False, lines=3)
                        
                        def toggle_prompt(checkbox):
                            return gr.update(visible=checkbox)
                        
                        use_additional_prompt.change(toggle_prompt, inputs=use_additional_prompt, outputs=additional_prompt_input)

                        with gr.Row():
                            generate_btn = gr.Button("ğŸ§¬ å¯åŠ¨å¤šè§†è§’ç”Ÿæˆ | GENERATE", variant="primary")
                            clear_btn = gr.Button("ğŸ”„ é‡ç½®ç³»ç»Ÿ | RESET", variant="secondary", interactive=False)

                    with gr.TabItem("ğŸ”— URL è¾“å…¥"):
                        manual_url_input = gr.Textbox(
                            label="å½±åƒ URL / Image URL", 
                            placeholder="https://example.com/scan.jpg",
                            info="è¯·è¾“å…¥åŒ»å­¦å½±åƒçš„ç›´æ¥é“¾æ¥ã€‚"
                        )
                        with gr.Accordion("âš™ï¸ é«˜çº§é€‰é¡¹ | Advanced Options", open=False):
                            with gr.Row():
                                use_additional_prompt_url = gr.Checkbox(label="å¯ç”¨å¢å¼ºæç¤ºè¯", value=False)
                                additional_prompt_input_url = gr.Textbox(label="æç¤ºè¯", placeholder="è¾“å…¥é¢å¤–çš„ç”Ÿç‰©ç‰¹å¾æè¿°", visible=False, lines=3)
                        
                        use_additional_prompt_url.change(toggle_prompt, inputs=use_additional_prompt_url, outputs=additional_prompt_input_url)

                        with gr.Row():
                            generate_url_btn = gr.Button("ğŸ§¬ å¯åŠ¨å¤šè§†è§’ç”Ÿæˆ (URL) | GENERATE", variant="primary")
                            clear_url_btn = gr.Button("ğŸ”„ é‡ç½®ç³»ç»Ÿ | RESET", variant="secondary", interactive=False)
                    
                    with gr.TabItem("ğŸ“‚ æ‰¹é‡ä¸Šä¼ "):
                        image_upload_input = gr.File(
                            file_count="multiple", 
                            label="æ‰¹é‡ä¸Šä¼ å½±åƒåºåˆ—",
                            file_types=["image"]
                        )
                        upload_btn = gr.Button("ğŸ“¥ åŠ è½½å½±åƒåºåˆ— | LOAD SEQUENCE", variant="primary")

                status_output = gr.Markdown("âœ… ç³»ç»Ÿå°±ç»ª | SYSTEM READY", elem_id="status")
                gallery = gr.Gallery(
                    label="å¤šè§†è§’åºåˆ— | Multi-view Sequence", 
                    columns=3, 
                    height="auto",
                    object_fit="contain",
                    show_label=True,
                    elem_id="gallery"
                )
                
            # Right Column: Reconstruction
            with gr.Column(scale=6, elem_classes="panel-container"):
                gr.Markdown("### ğŸ§Š ä¸‰ç»´å…¨æ¯é‡å»º | Holographic 3D Reconstruction")
                gr.Markdown("---")
                
                countdown_text = gr.Markdown("", elem_id="countdown")
                reconstruct_btn = gr.Button("ğŸ—ï¸ å¯åŠ¨ä¸‰ç»´é‡å»ºå¼•æ“ | INITIATE RECONSTRUCTION", variant="primary", interactive=False)
                
                with gr.Group():
                    model_output = gr.Model3D(
                        label="3D æ¨¡å‹é¢„è§ˆ | 3D Model Preview", 
                        height=600,
                        camera_position=(90, 90, 3), # Optional initial camera pos
                        interactive=False,
                        elem_id="model3d"
                    )
                
                download_model_btn = gr.DownloadButton("ğŸ’¾ å¯¼å‡ºæ¨¡å‹æ•°æ® | EXPORT MODEL", elem_classes="rounded-button", visible=False)
                
                with gr.Accordion("ğŸ› ï¸ å¼€å‘è€…æ§åˆ¶å° | Developer Console", open=False):
                    # Hidden controls
                    show_cam = gr.Checkbox(value=False, visible=False)
                    mask_sky = gr.Checkbox(value=False, visible=False)
                    mask_black_bg = gr.Checkbox(value=True, visible=False)
                    mask_white_bg = gr.Checkbox(value=True, visible=False)
                    
                    prediction_mode = gr.Radio(
                        choices=[("æ·±åº¦å›¾ä¸ç›¸æœºåˆ†æ”¯", "Depthmap and Camera Branch"), ("ç‚¹äº‘å›¾åˆ†æ”¯", "Pointmap Branch")],
                        value="Depthmap and Camera Branch",
                        label="é¢„æµ‹ç®—æ³•æ¨¡å¼"
                    )
                    
                    frame_filter = gr.Dropdown(choices=["All"], value="All", label="å±•ç¤ºæ¯å¼ å›¾çš„ç‚¹äº‘ï¼Œå¯èƒ½æœ‰ç‚¹å»¶è¿Ÿ")
                    
                    # Point Size Slider
                    point_size = gr.Slider(minimum=0.001, maximum=0.1, value=0.01, step=0.001, label="ç‚¹äº‘ç‚¹å¤§å° | Point Size", visible=True)
                
                # Confidence Threshold Slider (Visible)
                conf_thres = gr.Slider(minimum=0, maximum=100, value=20, step=0.1, label="ç½®ä¿¡åº¦è¿‡æ»¤ | Confidence Threshold", visible=True)
                
                update_btn = gr.Button("ğŸ”„ æ›´æ–°è§†å›¾ | UPDATE VIEW", variant="secondary", visible=False)

    # Event Handlers
    def on_generate_click(file_path, use_prompt, prompt_text):
        gr.Info("å›¾ç‰‡ç”Ÿæˆæ¨¡å¼ï¼šä¸Šä¼ å•å¼ å›¾ç‰‡ï¼ŒAIè‡ªåŠ¨ç”Ÿæˆå¤šè§†è§’å›¾åƒç”¨äºé‡å»ºã€‚", duration=5)
        if not file_path:
             gr.Warning("è¯·å…ˆä¸Šä¼ å›¾ç‰‡ã€‚")
             yield (
                gr.State(), None, "è¯·å…ˆä¸Šä¼ å›¾ç‰‡ã€‚", gr.update(interactive=False), None, gr.update(interactive=True), gr.update(interactive=False), gr.update()
             )
             return

        # 1. Disable generate, disable clear
        yield (
            gr.State(), # target_dir (no change yet)
            None,       # gallery
            gr.update(), # status
            gr.update(interactive=False), # reconstruct_btn
            file_path,        # url input
            gr.update(interactive=False), # generate_btn
            gr.update(interactive=False), # clear_btn
            gr.update()                   # frame_filter
        )
        
        url = upload_image_to_get_url(file_path)
        if not url:
             gr.Warning("å›¾ç‰‡ä¸Šä¼ å¤±è´¥ã€‚")
             yield (
                gr.State(), None, "å›¾ç‰‡ä¸Šä¼ å¤±è´¥ã€‚", gr.update(interactive=False), file_path, gr.update(interactive=True), gr.update(interactive=False), gr.update()
             )
             return

        yield (
            gr.State(), None, gr.update(), gr.update(interactive=False), file_path, gr.update(interactive=False), gr.update(interactive=False), gr.update()
        )
        
        # 2. Run generation
        session_dir, files, msg = generate_multiview_images(url, prompt_text if use_prompt else "")
        
        # 3. Handle result
        if "FAILED" in str(msg) or "ERROR" in str(msg) or "å¤±è´¥" in str(msg) or "æ— å…³" in str(msg) or "è¯·è¾“å…¥" in str(msg):
             # Failure case
             if msg == "MEDICAL_ERROR":
                 gr.Warning("æ‚¨ä¸Šä¼ çš„å›¾ç‰‡å’ŒåŒ»å­¦æ— å…³")
                 msg = "å°±ç»ªã€‚"
                 url_out = None
             elif msg == "Medical check failed (API Error).":
                 gr.Warning("åŒ»å­¦æ£€æµ‹å¤±è´¥ï¼ˆAPI é”™è¯¯ï¼‰è¯·ç¨åé‡è¯•ã€‚")
                 msg = "å°±ç»ªã€‚"
                 url_out = file_path
             elif msg == "è¯·è¾“å…¥å›¾ç‰‡ URLã€‚":
                 gr.Warning(msg)
                 msg = "å°±ç»ªã€‚"
                 url_out = file_path
             elif msg and str(msg).startswith("GENERATION_FAILED:"):
                 view_name = msg.split(":")[1]
                 gr.Warning(f"{view_name} ç”Ÿæˆå¤±è´¥ã€‚è¯·é‡è¯•ã€‚")
                 msg = f"ç”Ÿæˆ {view_name} å¤±è´¥ã€‚"
                 url_out = file_path
             elif msg and str(msg).startswith("GENERATION_ERROR:"):
                 parts = msg.split(":", 2)
                 view_name = parts[1]
                 error_detail = parts[2] if len(parts) > 2 else "æœªçŸ¥é”™è¯¯"
                 gr.Warning(f"ç”Ÿæˆ {view_name} å‡ºé”™: {error_detail}")
                 msg = f"ç”Ÿæˆ {view_name} å‡ºé”™ã€‚"
                 url_out = file_path
             else:
                 url_out = file_path

             yield (
                None, 
                None, 
                msg, 
                gr.update(interactive=False), 
                url_out,
                gr.update(interactive=True),  # Re-enable generate
                gr.update(interactive=False),  # Keep clear disabled
                gr.update(choices=["All"], value="All") # Reset frame filter
             )
        else:
             # Success case
             # Update frame filter choices
             all_files = [f"{i}: {os.path.basename(f)}" for i, f in enumerate(files)]
             frame_choices = ["All"] + all_files
             
             yield (
                session_dir,
                files,
                msg,
                gr.update(interactive=True), # Enable reconstruct
                file_path,
                gr.update(interactive=False), # Keep generate DISABLED
                gr.update(interactive=True),   # Enable clear
                gr.update(choices=frame_choices, value="All") # Update frame filter
             )

    def on_clear_click():
        return (
            None, # target_dir
            None, # gallery
            "å·²æ¸…ç©ºã€‚å‡†å¤‡ç”Ÿæˆã€‚", # status
            gr.update(interactive=False), # reconstruct_btn
            None,   # url input
            gr.update(interactive=True),  # Enable generate
            gr.update(interactive=False),  # Disable clear
            gr.update(choices=["All"], value="All") # Reset frame filter
        )

    def on_generate_url_click(url, use_prompt, prompt_text):
        gr.Info("URLç”Ÿæˆæ¨¡å¼ï¼šè¾“å…¥å›¾ç‰‡é“¾æ¥ï¼ŒAIè‡ªåŠ¨ç”Ÿæˆå¤šè§†è§’å›¾åƒç”¨äºé‡å»ºã€‚å½“å›¾ç‰‡URL-APIæ— æ³•è¿æ¥æ—¶å»ºè®®ä½¿ç”¨", duration=5)
        if not url:
             gr.Warning("è¯·è¾“å…¥å›¾ç‰‡ URLã€‚")
             yield (
                gr.State(), None, "è¯·è¾“å…¥å›¾ç‰‡ URLã€‚", gr.update(interactive=False), None, gr.update(interactive=True), gr.update(interactive=False), gr.update()
             )
             return

        # 1. Disable generate, disable clear
        yield (
            gr.State(), # target_dir (no change yet)
            None,       # gallery
            gr.update(), # status
            gr.update(interactive=False), # reconstruct_btn
            url,        # url input
            gr.update(interactive=False), # generate_btn
            gr.update(interactive=False), # clear_btn
            gr.update()                   # frame_filter
        )
        
        # 2. Run generation
        session_dir, files, msg = generate_multiview_images(url, prompt_text if use_prompt else "")
        
        # 3. Handle result
        if "FAILED" in str(msg) or "ERROR" in str(msg) or "å¤±è´¥" in str(msg) or "æ— å…³" in str(msg) or "è¯·è¾“å…¥" in str(msg):
             # Failure case
             if msg == "MEDICAL_ERROR":
                 gr.Warning("æ‚¨ä¸Šä¼ çš„å›¾ç‰‡å’ŒåŒ»å­¦æ— å…³")
                 msg = "å°±ç»ªã€‚"
                 url_out = ""
             elif msg == "Medical check failed (API Error).":
                 gr.Warning("åŒ»å­¦æ£€æµ‹å¤±è´¥ï¼ˆAPI é”™è¯¯ï¼‰è¯·ç¨åé‡è¯•ã€‚")
                 msg = "å°±ç»ªã€‚"
                 url_out = url
             elif msg == "è¯·è¾“å…¥å›¾ç‰‡ URLã€‚":
                 gr.Warning(msg)
                 msg = "å°±ç»ªã€‚"
                 url_out = url
             elif msg and str(msg).startswith("GENERATION_FAILED:"):
                 view_name = msg.split(":")[1]
                 gr.Warning(f"{view_name} ç”Ÿæˆå¤±è´¥ã€‚è¯·é‡è¯•ã€‚")
                 msg = f"ç”Ÿæˆ {view_name} å¤±è´¥ã€‚"
                 url_out = url
             elif msg and str(msg).startswith("GENERATION_ERROR:"):
                 parts = msg.split(":", 2)
                 view_name = parts[1]
                 error_detail = parts[2] if len(parts) > 2 else "æœªçŸ¥é”™è¯¯"
                 gr.Warning(f"ç”Ÿæˆ {view_name} å‡ºé”™: {error_detail}")
                 msg = f"ç”Ÿæˆ {view_name} å‡ºé”™ã€‚"
                 url_out = url
             else:
                 url_out = url

             yield (
                None, 
                None, 
                msg, 
                gr.update(interactive=False), 
                url_out,
                gr.update(interactive=True),  # Re-enable generate
                gr.update(interactive=False),  # Keep clear disabled
                gr.update(choices=["All"], value="All") # Reset frame filter
             )
        else:
             # Success case
             # Update frame filter choices
             all_files = [f"{i}: {os.path.basename(f)}" for i, f in enumerate(files)]
             frame_choices = ["All"] + all_files
             
             yield (
                session_dir,
                files,
                msg,
                gr.update(interactive=True), # Enable reconstruct
                url,
                gr.update(interactive=False), # Keep generate DISABLED
                gr.update(interactive=True),   # Enable clear
                gr.update(choices=frame_choices, value="All") # Update frame filter
             )

    def on_clear_url_click():
        return (
            None, # target_dir
            None, # gallery
            "å·²æ¸…ç©ºã€‚å‡†å¤‡ç”Ÿæˆã€‚", # status
            gr.update(interactive=False), # reconstruct_btn
            "",   # url input
            gr.update(interactive=True),  # Enable generate
            gr.update(interactive=False),  # Disable clear
            gr.update(choices=["All"], value="All") # Reset frame filter
        )

    generate_btn.click(
        on_generate_click,
        inputs=[image_url_input, use_additional_prompt, additional_prompt_input],
        outputs=[target_dir_state, gallery, status_output, reconstruct_btn, image_url_input, generate_btn, clear_btn, frame_filter]
    )
    
    clear_btn.click(
        on_clear_click,
        outputs=[target_dir_state, gallery, status_output, reconstruct_btn, image_url_input, generate_btn, clear_btn, frame_filter]
    )

    generate_url_btn.click(
        on_generate_url_click,
        inputs=[manual_url_input, use_additional_prompt_url, additional_prompt_input_url],
        outputs=[target_dir_state, gallery, status_output, reconstruct_btn, manual_url_input, generate_url_btn, clear_url_btn, frame_filter]
    )
    
    clear_url_btn.click(
        on_clear_url_click,
        outputs=[target_dir_state, gallery, status_output, reconstruct_btn, manual_url_input, generate_url_btn, clear_url_btn, frame_filter]
    )
    
    upload_btn.click(
        handle_local_upload,
        inputs=[image_upload_input],
        outputs=[target_dir_state, gallery, status_output, reconstruct_btn]
    )
    
    def on_reconstruct(target_dir, conf, cam, sky, black, white, mode, frame_filter, point_size):
        # 1. Disable buttons immediately
        yield gr.update(interactive=False, variant="secondary"), "â³ å¼€å§‹é‡å»º...", None, gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(visible=False), gr.update(visible=False)
        
        # 2. Run inference
        try:
            glb_path = run_pi3_inference(target_dir, conf, cam, sky, black, white, mode, frame_filter, point_size)
        except Exception as e:
            # Restore buttons on error. 
            yield gr.update(interactive=True, variant="primary"), f"âŒ é”™è¯¯: {e}", None, gr.update(interactive=True), gr.update(interactive=True), gr.update(interactive=True), gr.update(visible=False), gr.update(visible=False)
            return

        # 3. Countdown loop
        for i in range(30, 0, -1):
            yield gr.update(interactive=False, variant="secondary"), f"âš ï¸ å†·å´ä¸­: è¯·ç­‰å¾… {i} ç§’...", glb_path, gr.update(interactive=False), gr.update(interactive=False), gr.update(interactive=False), gr.update(value=glb_path, visible=True), gr.update(visible=True)
            time.sleep(1)
            
        # 4. Re-enable. 
        yield gr.update(interactive=True, variant="primary"), "âœ… å‡†å¤‡å¥½è¿›è¡Œæ–°çš„é‡å»º", glb_path, gr.update(interactive=False), gr.update(interactive=True), gr.update(interactive=True), gr.update(value=glb_path, visible=True), gr.update(visible=True)

    reconstruct_btn.click(
        on_reconstruct,
        inputs=[target_dir_state, conf_thres, show_cam, mask_sky, mask_black_bg, mask_white_bg, prediction_mode, frame_filter, point_size],
        outputs=[reconstruct_btn, countdown_text, model_output, generate_btn, clear_btn, upload_btn, download_model_btn, update_btn]
    )
    
    # Update visualization when update button is clicked
    viz_inputs = [target_dir_state, conf_thres, show_cam, mask_sky, mask_black_bg, mask_white_bg, prediction_mode, frame_filter, point_size]
    update_btn.click(
        update_visualization,
        inputs=viz_inputs,
        outputs=[model_output, download_model_btn]
    )

if __name__ == "__main__":
    # share=True requires downloading frpc which might fail in some environments.
    # Setting share=False to avoid startup errors.
    # Port 6006 might be busy, using 6008
    demo.queue().launch(server_name="0.0.0.0", server_port=6008, share=False)
